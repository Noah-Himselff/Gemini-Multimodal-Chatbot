{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1- Getting started"
      ],
      "metadata": {
        "id": "fzwD9ur2LvUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio\n",
        "!pip install ffmpeg-python\n",
        "!pip install google-generative-ai"
      ],
      "metadata": {
        "id": "x7KN8azh5rGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "import os\n",
        "import json\n",
        "import io\n",
        "import ffmpeg\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from IPython.display import HTML, display\n",
        "from google.colab.output import eval_js\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "oKbzOuOd5ptc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY=('AIzaSyBusNIqT-avOTqEdNQe7AG8a1O5oaKCqQM')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "llm = genai.GenerativeModel('gemini-pro')\n",
        "response = llm.generate_content(\"Write a story about a magic backpack.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "_qdr-jplWq_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "0182c10c-3a0c-4a29-db1a-f40884485024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the bustling metropolis of Willow Creek, where towering skyscrapers cast long shadows upon the cobblestone streets, there resided an unassuming young girl named Anya. With her fiery red hair and piercing blue eyes, she was known for her infectious laughter and adventurous spirit.\n",
            "\n",
            "But one ordinary afternoon, as Anya skipped through the town square, her life took an extraordinary turn. Amidst the vibrant market stalls and the clamor of street musicians, she spotted a peculiar backpack tucked away in a dusty antique shop. Its emerald-green leather gleamed under the dim lights, and its intricate carvings hinted at a hidden power.\n",
            "\n",
            "Unable to resist its allure, Anya ventured inside and gingerly picked up the backpack. As her fingers brushed against its surface, a surge of warmth coursed through her body. Suddenly, the backpack began to glow, and an ethereal whisper echoed in her ear.\n",
            "\n",
            "\"I am Alora, the guardian of secrets and magic. I have chosen you, Anya, to be my new master.\"\n",
            "\n",
            "Anya's heart skipped a beat. She had stumbled upon a magical artifact, a backpack that could grant her unimaginable powers. With trembling hands, she fastened the backpack onto her shoulders and stepped out into the vibrant city.\n",
            "\n",
            "At first, Alora's abilities were subtle. Anya noticed that she could vanish objects from sight, making them disappear into the backpack's enchanted interior. She could also create illusions, transforming objects and people into anything she could imagine.\n",
            "\n",
            "But as Anya's confidence grew, so did her explorations of the backpack's powers. She could soar through the air, defying gravity with ease. She could rewind time, correcting mistakes and living moments over again. And most astoundingly, she could control the elements, summoning storms and calming the raging seas.\n",
            "\n",
            "As Anya delved deeper into the realms of magic, she realized that Alora held a far more profound secret than she had ever imagined. Within the backpack resided a gateway to other worlds, each with its own unique wonders and challenges.\n",
            "\n",
            "One day, Anya found herself transported to a realm of shimmering crystals and sparkling streams. Here, she encountered wise old creatures who taught her the secrets of ancient spells and the power of kindness. In another realm, she ventured into a treacherous labyrinth, where her courage and determination were tested to the limit.\n",
            "\n",
            "But with Alora by her side, Anya overcame every obstacle with grace and determination. She used her newfound powers to help those in need, healing the sick, protecting the innocent, and fighting against injustice.\n",
            "\n",
            "As the sun began to set on Willow Creek, Anya returned to the market square. With a heavy heart, she realized that it was time to part ways with Alora. The backpack had served its purpose, and it was now time for her to return to her own world.\n",
            "\n",
            "With a tear in her eye, Anya thanked Alora for the extraordinary adventure. As she bid farewell to her magical companion, Anya knew that the memories they had created would last a lifetime. And so, she left the antique shop and stepped out into the bustling streets, forever changed by the secrets and magic that Alora had revealed to her.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.generate_content(\"what is nlp\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "rwI_rb4IMF-x",
        "outputId": "51e18198-7903-444a-99c3-8f4a16780f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Natural Language Processing (NLP)**\n",
            "\n",
            "NLP is a subfield of artificial intelligence (AI) that deals with the understanding and manipulation of human language. Its goal is to enable computers to communicate with humans in natural language (i.e., the way humans communicate with each other), and to understand, generate, and analyze text and speech data.\n",
            "\n",
            "**Key Concepts:**\n",
            "\n",
            "* **Text and Speech Processing:** Acquiring, pre-processing, and analyzing text and speech data.\n",
            "* **Natural Language Understanding:** Extracting meaning and insights from language, including sentiment analysis, topic modeling, and semantic analysis.\n",
            "* **Natural Language Generation:** Creating human-like text and speech from structured data.\n",
            "* **Machine Learning Techniques:** Using algorithms to train NLP models on large datasets for various tasks.\n",
            "* **Applications:** NLP has wide-ranging applications in industries such as:\n",
            "    * Customer service: Chatbots and virtual assistants\n",
            "    * Healthcare: Diagnosis support and patient record analysis\n",
            "    * Finance: Fraud detection and risk analysis\n",
            "    * Language translation: Machine translation and language learning\n",
            "    * Search engines: Document retrieval and ranking\n",
            "\n",
            "**Benefits of NLP:**\n",
            "\n",
            "* **Enhanced Communication:** Enables seamless interaction between humans and machines.\n",
            "* **Information Extraction:** Facilitates the extraction of valuable insights from text and speech data.\n",
            "* **Decision-making:** Provides data-driven insights for better decision-making.\n",
            "* **Automation:** Automates repetitive text-based tasks, freeing up human resources for more complex work.\n",
            "* **Improved User Experience:** Enhances user interactions through natural and intuitive interfaces.\n",
            "\n",
            "**Challenges:**\n",
            "\n",
            "* **Ambiguity and Context:** Language is often ambiguous, making it difficult for computers to always interpret it correctly.\n",
            "* **Data Quality and Bias:** NLP models rely heavily on data, and biased or inaccurate data can lead to biased results.\n",
            "* **Computational Complexity:** Processing and analyzing large amounts of text and speech data can be computationally intensive.\n",
            "* **Cultural and Language Barriers:** NLP models may not perform well across different cultures and languages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = 'YOUR_GOOGLE_API_KEY'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "chat = genai.GenerativeModel('gemini-pro').start_chat(history=[])\n",
        "\n",
        "# Path for storing chat history\n",
        "HISTORY_FILE = 'chat_history.json'"
      ],
      "metadata": {
        "id": "VkqxYKmwk67H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Audio Utilities"
      ],
      "metadata": {
        "id": "fIvESZa1LqKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "  };\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "sleep(2000).then(() => {\n",
        "  resolve(base64data.toString())\n",
        "});\n",
        "}\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "    display(HTML(AUDIO_HTML))\n",
        "    data = eval_js(\"data\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    process = (ffmpeg\n",
        "        .input('pipe:0')\n",
        "        .output('pipe:1', format='wav')\n",
        "        .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "    )\n",
        "    output, err = process.communicate(input=binary)\n",
        "\n",
        "    riff_chunk_size = len(output) - 8\n",
        "    q = riff_chunk_size\n",
        "    b = []\n",
        "    for i in range(4):\n",
        "        q, r = divmod(q, 256)\n",
        "        b.append(r)\n",
        "\n",
        "    riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "    sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "    return audio, sr, output\n",
        "\n",
        "def transcriber(audio_data):\n",
        "    recognizer = sr.Recognizer()\n",
        "    try:\n",
        "        audio_file = io.BytesIO(audio_data)\n",
        "        with sr.AudioFile(audio_file) as source:\n",
        "            audio = recognizer.record(source)\n",
        "        return recognizer.recognize_google(audio)\n",
        "    except Exception as e:\n",
        "        print('Error transcribing audio:', str(e))\n",
        "        return None"
      ],
      "metadata": {
        "id": "Rm6FIQ4hk-Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- Chat utilities"
      ],
      "metadata": {
        "id": "CkiUJjvpMHi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chat_response(user_input, history):\n",
        "    chat.history = [{\"parts\": [{\"text\": entry[0]}], \"role\": \"user\"} if i % 2 == 0 else {\"parts\": [{\"text\": entry[0]}], \"role\": \"model\"} for i, entry in enumerate(history)]\n",
        "    response = chat.send_message(user_input)\n",
        "    response.resolve()\n",
        "    return response.text\n",
        "\n",
        "def load_history():\n",
        "    if os.path.exists(HISTORY_FILE):\n",
        "        with open(HISTORY_FILE, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return []\n",
        "\n",
        "def save_history(history):\n",
        "    with open(HISTORY_FILE, 'w') as f:\n",
        "        json.dump(history, f)"
      ],
      "metadata": {
        "id": "XqIp-rCjlF8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_text():\n",
        "    conversation_history = load_history()\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Enter your message: \")\n",
        "        conversation_history.append((user_input,))\n",
        "\n",
        "        response_text = get_chat_response(user_input, conversation_history)\n",
        "        print(\"Gemini: \", response_text)\n",
        "        conversation_history.append((response_text,))\n",
        "\n",
        "        user_continue = input(\"Do you want to continue the conversation? (yes/no): \").strip().lower()\n",
        "        if user_continue != 'yes':\n",
        "            break\n",
        "\n",
        "        user_choice = input(\"Do you want to switch input method? (voice/text): \").strip().lower()\n",
        "        if user_choice == 'voice':\n",
        "            chat_with_transcription()\n",
        "            break\n",
        "\n",
        "    save_history(conversation_history)\n",
        "\n",
        "def chat_with_transcription():\n",
        "    conversation_history = load_history()\n",
        "\n",
        "    while True:\n",
        "        print(\"Please record your message (press the button to start and stop recording)...\")\n",
        "        audio, sample_rate, audio_data = get_audio()\n",
        "        transcription = transcriber(audio_data)\n",
        "\n",
        "        if transcription:\n",
        "            print(\"You: \", transcription)\n",
        "            conversation_history.append((transcription,))\n",
        "\n",
        "            response_text = get_chat_response(transcription, conversation_history)\n",
        "            print(\"Gemini: \", response_text)\n",
        "            conversation_history.append((response_text,))\n",
        "\n",
        "        user_continue = input(\"Do you want to continue the conversation? (yes/no): \").strip().lower()\n",
        "        if user_continue != 'yes':\n",
        "            break\n",
        "\n",
        "        user_choice = input(\"Do you want to switch input method? (voice/text): \").strip().lower()\n",
        "        if user_choice == 'text':\n",
        "            chat_with_text()\n",
        "            break\n",
        "\n",
        "    save_history(conversation_history)"
      ],
      "metadata": {
        "id": "9aVeJXv_lLKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4- Testing out"
      ],
      "metadata": {
        "id": "vtP2fr-sMPRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def start_chat():\n",
        "    while True:\n",
        "        choice = input(\"Would you like to start with voice or text input? (voice/text): \").strip().lower()\n",
        "        if choice == 'voice':\n",
        "            chat_with_transcription()\n",
        "        elif choice == 'text':\n",
        "            chat_with_text()\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter 'voice' or 'text'.\")\n",
        "            continue\n",
        "\n",
        "        user_continue = input(\"Do you want to start a new session? (yes/no): \").strip().lower()\n",
        "        if user_continue != 'yes':\n",
        "            break\n",
        "\n",
        "# Start the chat\n",
        "start_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AcpgB9NOgYMJ",
        "outputId": "4c16a084-bfd4-41fe-f979-7f8c4cd4757c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Would you like to start with voice or text input? (voice/text): text\n",
            "Enter your message: what is nlp\n",
            "Gemini:  **NLP** stands for **Natural Language Processing**. It is a subfield of artificial intelligence that gives computers the ability to understand and generate human language.\n",
            "\n",
            "NLP enables computers to:\n",
            "\n",
            "* **Understand the meaning of text:** Identify the main ideas, relationships, and sentiments expressed in text.\n",
            "* **Generate text:** Produce human-like text, such as summaries, translations, and chatbots.\n",
            "* **Translate languages:** Convert text from one language to another while preserving its meaning.\n",
            "* **Classify and categorize text:** Assign labels or categories to text based on its content.\n",
            "* **Extract information from text:** Identify and extract specific pieces of information, such as names, dates, and locations.\n",
            "\n",
            "NLP is used in a wide range of applications, including:\n",
            "\n",
            "* **Search engines:** NLP helps search engines understand and rank web pages based on their relevance to user queries.\n",
            "* **Machine translation:** NLP enables computers to translate text from one language to another.\n",
            "* **Chatbots and virtual assistants:** NLP allows computers to engage in natural language conversations with humans.\n",
            "* **Text summarization:** NLP can automatically generate summaries of long pieces of text.\n",
            "* **Spam filtering:** NLP helps identify and filter out spam emails.\n",
            "\n",
            "NLP is a rapidly growing field, and new applications are being developed all the time. As NLP technology continues to improve, we can expect to see even more innovative and groundbreaking applications in the future.\n",
            "Do you want to continue the conversation? (yes/no): yes\n",
            "Do you want to switch input method? (voice/text): voice\n",
            "Please record your message (press the button to start and stop recording)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "  };\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {\n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data);\n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "};\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "sleep(2000).then(() => {\n",
              "  resolve(base64data.toString())\n",
              "});\n",
              "}\n",
              "});\n",
              "\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:  can you tell me what are the branches of NLP and also while you're at it tell me if llm or large language models are considered a branch of NLP or a different type of artificial intelligence branch\n",
            "Gemini:  **Branches of Natural Language Processing (NLP):**\n",
            "\n",
            "* **Machine translation:** Translating text from one language to another.\n",
            "* **Text summarization:** Condensing large amounts of text into shorter, more concise summaries.\n",
            "* **Named entity recognition:** Identifying and classifying named entities in text, such as people, places, and organizations.\n",
            "* **Part-of-speech tagging:** Labeling each word in a sentence with its grammatical role (e.g., noun, verb, adjective).\n",
            "* **Syntactic parsing:** Analyzing the grammatical structure of sentences.\n",
            "* **Semantic analysis:** Understanding the meaning of text, including identifying sentiment and extracting relationships between entities.\n",
            "* **Speech recognition:** Converting spoken language into text.\n",
            "* **Natural language generation:** Generating human-like text from structured data or instructions.\n",
            "* **Question answering:** Answering questions based on a given text or knowledge base.\n",
            "* **Dialogue systems:** Enabling computers to engage in natural language conversations with humans.\n",
            "\n",
            "**Are LLMs a Branch of NLP or a Different Type of AI Branch?**\n",
            "\n",
            "Large language models (LLMs) are a type of artificial intelligence that has been trained on massive datasets of text. They are considered to be a subfield of NLP, as they are specifically designed to process and understand natural language.\n",
            "\n",
            "LLMs have shown impressive performance in a wide range of NLP tasks, including machine translation, text summarization, question answering, and dialogue generation. They are also being used to develop new applications, such as chatbots and virtual assistants.\n",
            "\n",
            "While LLMs are still under development, they have the potential to revolutionize the way we interact with computers and access information.\n",
            "\n",
            "Therefore, LLMs can be considered a branch of NLP, as they are specifically designed to process and understand natural language. However, they also represent a significant advancement in the field of AI, as they have the potential to solve complex problems that were previously difficult or impossible for computers to handle.\n",
            "Do you want to continue the conversation? (yes/no): yes\n",
            "Do you want to switch input method? (voice/text): voice\n",
            "Please record your message (press the button to start and stop recording)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "  };\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {\n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data);\n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "};\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "sleep(2000).then(() => {\n",
              "  resolve(base64data.toString())\n",
              "});\n",
              "}\n",
              "});\n",
              "\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:  what are multimodal llms and is a voice to text and text to text llm model considered a multimodal\n",
            "Gemini:  **Multimodal LLMs**\n",
            "\n",
            "Multimodal LLMs are large language models that have been trained on multiple modalities of data, such as text, images, audio, and video. This allows them to understand and generate content across different modalities.\n",
            "\n",
            "For example, a multimodal LLM could:\n",
            "\n",
            "* Generate a text description of an image.\n",
            "* Translate spoken language into text.\n",
            "* Create a video from a text prompt.\n",
            "\n",
            "**Voice-to-Text and Text-to-Text LLM Models**\n",
            "\n",
            "A voice-to-text LLM model is a type of multimodal LLM that can convert spoken language into text. It is trained on a large dataset of audio recordings and their corresponding transcripts.\n",
            "\n",
            "A text-to-text LLM model is a type of multimodal LLM that can translate text from one language to another, or generate new text based on a given prompt. It is trained on a large dataset of text in multiple languages.\n",
            "\n",
            "**Are Voice-to-Text and Text-to-Text LLM Models Considered Multimodal?**\n",
            "\n",
            "Yes, voice-to-text and text-to-text LLM models are considered multimodal because they can process and generate content across different modalities.\n",
            "\n",
            "* Voice-to-text LLM models can convert spoken language (audio) into text.\n",
            "* Text-to-text LLM models can translate text from one language to another (different languages) or generate new text (text generation).\n",
            "\n",
            "Therefore, both voice-to-text and text-to-text LLM models are considered to be multimodal LLMs.\n",
            "Do you want to continue the conversation? (yes/no): yes\n",
            "Do you want to switch input method? (voice/text): voice\n",
            "Please record your message (press the button to start and stop recording)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "  };\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {\n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data);\n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "};\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "sleep(2000).then(() => {\n",
              "  resolve(base64data.toString())\n",
              "});\n",
              "}\n",
              "});\n",
              "\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:  no I meant that is an element that has both voice to text function and answering text to text considered a multimodal I meant that's the model has both of them at the same time and if yes tell me what other things can I add to my model to make it bigger and if know what are multiples\n",
            "Gemini:  **Yes, a model that has both voice-to-text and text-to-text capabilities is considered a multimodal model.**\n",
            "\n",
            "**Other things you can add to your model to make it bigger:**\n",
            "\n",
            "* **More training data:** The more data your model is trained on, the better it will perform. You can add more text data, audio data, and/or video data to your training dataset.\n",
            "* **More parameters:** The number of parameters in a model determines its capacity to learn and represent complex relationships in the data. You can increase the number of parameters in your model by adding more layers or increasing the size of the hidden layers.\n",
            "* **More modalities:** Adding more modalities to your model will make it more versatile and able to handle a wider range of tasks. For example, you could add image processing capabilities or video processing capabilities to your model.\n",
            "* **Specialized modules:** You can add specialized modules to your model to improve its performance on specific tasks. For example, you could add a named entity recognition module or a question answering module.\n",
            "\n",
            "**Multiples**\n",
            "\n",
            "In the context of machine learning models, the term \"multiples\" can refer to:\n",
            "\n",
            "* **Model ensembles:** An ensemble is a group of models that are trained on the same data but with different hyperparameters or architectures. The predictions of the individual models are combined to produce a final prediction. Ensembling can help to improve the accuracy and robustness of a model.\n",
            "* **Model variants:** Model variants are different versions of a model that have been trained on different datasets or with different hyperparameters. This can be useful for exploring different design choices and finding the best model for a particular task.\n",
            "\n",
            "You can experiment with different combinations of these techniques to create a larger and more powerful multimodal model.\n",
            "Do you want to continue the conversation? (yes/no): no\n",
            "Do you want to start a new session? (yes/no): yes\n",
            "Would you like to start with voice or text input? (voice/text): voice\n",
            "Please record your message (press the button to start and stop recording)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "  };\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {\n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data);\n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "};\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "sleep(2000).then(() => {\n",
              "  resolve(base64data.toString())\n",
              "});\n",
              "}\n",
              "});\n",
              "\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You:  who is Donald J Trump\n",
            "Gemini:  **Donald John Trump** is an American politician, businessman, and media personality who served as the 45th president of the United States from 2017 to 2021.\n",
            "\n",
            "**Early Life and Career:**\n",
            "\n",
            "* Born on June 14, 1946, in Queens, New York City\n",
            "* Graduated from the Wharton School of the University of Pennsylvania with a bachelor's degree in economics\n",
            "* Took over the family real estate business, The Trump Organization, in 1971\n",
            "* Developed and invested in numerous high-profile real estate projects, including Trump Tower in New York City and Mar-a-Lago in Palm Beach, Florida\n",
            "\n",
            "**Political Career:**\n",
            "\n",
            "* Announced his candidacy for president in June 2015\n",
            "* Won the Republican nomination in 2016\n",
            "* Defeated Hillary Clinton in the general election and was inaugurated as president on January 20, 2017\n",
            "* Lost the 2020 presidential election to Joe Biden\n",
            "\n",
            "**Presidency:**\n",
            "\n",
            "* Enacted tax cuts, reduced regulations, and appointed conservative judges\n",
            "* Implemented a travel ban on citizens from several Muslim-majority countries\n",
            "* Withdrew the United States from the Paris climate agreement and the Iran nuclear deal\n",
            "* Imposed tariffs on goods imported from China\n",
            "\n",
            "**Post-Presidency:**\n",
            "\n",
            "* Continues to be a vocal figure in American politics\n",
            "* Launched his own social media platform, Truth Social\n",
            "* Has repeatedly made false claims that the 2020 election was stolen from him\n",
            "\n",
            "**Personal Life:**\n",
            "\n",
            "* Married three times: Ivana Zelníčková (1977-1992), Marla Maples (1993-1999), and Melania Knauss (2005-present)\n",
            "* Has five children: Donald Jr., Ivanka, Eric, Tiffany, and Barron\n",
            "Do you want to continue the conversation? (yes/no): yes\n",
            "Do you want to switch input method? (voice/text): voice\n",
            "Please record your message (press the button to start and stop recording)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "  };\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {\n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data);\n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "};\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "sleep(2000).then(() => {\n",
              "  resolve(base64data.toString())\n",
              "});\n",
              "}\n",
              "});\n",
              "\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You:  can you tell me what are his main sources of income and what is his current net worth also while you're at it I want you to tell me that according to Forbes what is his current ranking among Americans most influential people\n",
            "Gemini:  **Main Sources of Income:**\n",
            "\n",
            "Donald Trump's main sources of income have been through:\n",
            "\n",
            "* **Real estate development and investment:** Trump has developed and invested in numerous high-profile real estate projects, such as Trump Tower in New York City and Mar-a-Lago in Palm Beach, Florida.\n",
            "* **Hospitality:** Trump owns and operates a portfolio of hotels, resorts, and golf courses around the world.\n",
            "* **Licensing and branding:** Trump has licensed his name and brand to a wide range of products and services, including clothing, accessories, and home goods.\n",
            "* **Media and entertainment:** Trump has hosted the reality television show \"The Apprentice\" and has made numerous other media appearances.\n",
            "* **Books:** Trump has written several books, including \"The Art of the Deal\" and \"Think Big and Kick Ass in Business and Life.\"\n",
            "\n",
            "**Current Net Worth:**\n",
            "\n",
            "According to Forbes, Donald Trump's current net worth is estimated to be **$2.5 billion** as of February 28, 2023. However, it's important to note that net worth estimates can vary depending on the source and methodology used.\n",
            "\n",
            "**Forbes Ranking:**\n",
            "\n",
            "Forbes ranks Donald Trump as the **129th** most influential person in the world in 2023. He is also ranked as the **17th** most influential person in the United States.\n",
            "Do you want to continue the conversation? (yes/no): no\n",
            "Do you want to start a new session? (yes/no): no\n"
          ]
        }
      ]
    }
  ]
}